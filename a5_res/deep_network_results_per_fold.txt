Deep Neural Network Results with L1 Regularization - Per Fold Results
--------------------------------------------


Results for Fold 0:
               fold  reg_factor  ce_loss     mse  accuracy
architecture                                              
[128, 64, 32]   0.0       0.001  13.9535  0.1395    0.8605
[32, 32, 32]    0.0       0.001  14.6512  0.1465    0.8535
[32, 64, 128]   0.0       0.001  15.1163  0.1512    0.8488
[64, 32, 64]    0.0       0.001  13.9535  0.1395    0.8605
[64, 32]        0.0       0.001  13.7209  0.1372    0.8628

Results for Fold 1:
               fold  reg_factor  ce_loss     mse  accuracy
architecture                                              
[128, 64, 32]   1.0       0.001  13.4884  0.1349    0.8651
[32, 32, 32]    1.0       0.001  11.3953  0.1140    0.8860
[32, 64, 128]   1.0       0.001  12.3256  0.1233    0.8767
[64, 32, 64]    1.0       0.001  11.8605  0.1186    0.8814
[64, 32]        1.0       0.001  13.2558  0.1326    0.8674

Results for Fold 2:
               fold  reg_factor  ce_loss     mse  accuracy
architecture                                              
[128, 64, 32]   2.0       0.001  14.8837  0.1488    0.8512
[32, 32, 32]    2.0       0.001  15.5814  0.1558    0.8442
[32, 64, 128]   2.0       0.001  15.1163  0.1512    0.8488
[64, 32, 64]    2.0       0.001  14.1860  0.1419    0.8581
[64, 32]        2.0       0.001  15.1163  0.1512    0.8488

Results for Fold 3:
               fold  reg_factor  ce_loss     mse  accuracy
architecture                                              
[128, 64, 32]   3.0       0.001  13.2558  0.1326    0.8674
[32, 32, 32]    3.0       0.001  12.5581  0.1256    0.8744
[32, 64, 128]   3.0       0.001  12.7907  0.1279    0.8721
[64, 32, 64]    3.0       0.001  13.7209  0.1372    0.8628
[64, 32]        3.0       0.001  14.1860  0.1419    0.8581

Results for Fold 4:
               fold  reg_factor  ce_loss     mse  accuracy
architecture                                              
[128, 64, 32]   4.0       0.001  14.2191  0.1422    0.8578
[32, 32, 32]    4.0       0.001  15.1515  0.1515    0.8485
[32, 64, 128]   4.0       0.001  12.5874  0.1259    0.8741
[64, 32, 64]    4.0       0.001  16.0839  0.1608    0.8392
[64, 32]        4.0       0.001  14.6853  0.1469    0.8531
